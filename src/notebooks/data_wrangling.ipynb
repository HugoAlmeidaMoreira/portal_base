{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import & Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "# Define the range of years\n",
    "start_year = 2012\n",
    "end_year = 2024\n",
    "\n",
    "# Function to read a single Excel file\n",
    "def read_excel_file(year):\n",
    "    file_path = f\"F:/portal_base/data/raw/contratospub{year}.xlsx\"\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "# Use ThreadPoolExecutor to read files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Map the read_excel_file function to the range of years\n",
    "    df_list = list(executor.map(read_excel_file, range(start_year, end_year + 1)))\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df.head()\n",
    "\n",
    "\n",
    "# Save as pickle file\n",
    "pkl_output_path = \"F:/portal_base/data/processed/combined_data.pkl\"\n",
    "combined_df.to_pickle(pkl_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the combined DataFrame from the pickle file\n",
    "pkl_input_path = \"F:/portal_base/data/processed/combined_data.pkl\"\n",
    "\n",
    "combined_df = pd.read_pickle(pkl_input_path)\n",
    "\n",
    "# Drop columns\n",
    "combined_df = combined_df.drop(columns=['Observacoes', 'numAcordoQuadro', 'DescrAcordoQuadro', 'concorrentes', 'regime', 'fundamentacao', 'nAnuncio', 'TipoAnuncio', 'idINCM', 'ProcedimentoCentralizado', 'dataFechoContrato', 'linkPecasProc', 'CritMateriais', 'tipoFimContrato', 'justifNReducEscrContrato', 'dataPublicacao'])\n",
    "\n",
    "# Separar a coluna adjudicante usando a primeira ocorrência de \" - \"\n",
    "combined_df['nif_adjudicante'] = combined_df['adjudicante'].str.split(' - ', n=1, expand=True)[0]\n",
    "combined_df['nome_adjudicante'] = combined_df['adjudicante'].str.split(' - ', n=1, expand=True)[1]\n",
    "\n",
    "# Remover a coluna original\n",
    "combined_df.drop(columns=['adjudicante'], inplace=True)\n",
    "\n",
    "# Separar a coluna cpv em código e descrição\n",
    "combined_df[['cpv_código', 'cpv_descricao']] = combined_df['cpv'].str.split(' - ', n=1, expand=True)\n",
    "\n",
    "# Criar a coluna cpv_division a partir dos dois primeiros números do cpv_código\n",
    "combined_df['cpv_division'] = combined_df['cpv_código'].str[:2]\n",
    "\n",
    "# Remover a coluna original\n",
    "combined_df.drop(columns=['cpv'], inplace=True)\n",
    "\n",
    "# Função para processar a geografia\n",
    "def process_geografia(entry):\n",
    "    if not isinstance(entry, str):\n",
    "        return 'Desconhecido', 'Desconhecido'\n",
    "    # Separar múltiplos locais pelo separador \"|\"\n",
    "    locais = entry.split(' | ')\n",
    "    # Extrair apenas NUTS I e NUTS II\n",
    "    nuts_ii = set()\n",
    "    for local in locais:\n",
    "        niveis = local.split(', ')\n",
    "        if len(niveis) >= 2:\n",
    "            nuts_ii.add(niveis[1])  # Pegamos no NUTS II\n",
    "        else:\n",
    "            nuts_ii.add('Portugal')  # Apenas Portugal (NUTS I)\n",
    "    \n",
    "    # Decidir o âmbito_geo\n",
    "    if len(nuts_ii) == 1:\n",
    "        if 'Portugal' in nuts_ii:\n",
    "            return 'Portugal', 'Nacional'\n",
    "        else:\n",
    "            return list(nuts_ii)[0], list(nuts_ii)[0]\n",
    "    else:\n",
    "        return list(nuts_ii)[0], 'Múltiplos'\n",
    "\n",
    "# Adicionar barra de progresso com tqdm\n",
    "tqdm.pandas(desc=\"Processando geografia\")\n",
    "\n",
    "# Aplicar a função à coluna geografia com tqdm\n",
    "combined_df[['NUTS', 'ambito_geo']] = combined_df['localExecucao'].progress_apply(process_geografia).apply(pd.Series)\n",
    "\n",
    "# Resultado final\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle file\n",
    "pkl_output_path = \"F:/portal_base/data/processed/portal_base_trimmed.pkl\"\n",
    "combined_df.to_pickle(pkl_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
